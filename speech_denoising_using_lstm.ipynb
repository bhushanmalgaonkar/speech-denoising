{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "speech-denoising-using-lstm.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "TRJwZmWFZVUH",
        "colab_type": "code",
        "outputId": "ed0b3c6d-0812-48f9-f3a9-b435cb3ebc12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bBe8sG2ZaCm1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "base_path = './drive/My Drive/Colab Notebooks/Speech Denoising/LotOfData/'\n",
        "\n",
        "base_path_train = base_path + 'tr/'\n",
        "base_path_val = base_path + 'v/'\n",
        "base_path_test = base_path + 'te/'\n",
        "\n",
        "base_path_pickle = base_path + 'pickle/'\n",
        "\n",
        "base_path_result = base_path + 'result/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VVGaYrEfaEWU",
        "colab_type": "code",
        "outputId": "9d5b8af3-42c2-41d6-c2a2-a3aee599dc2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install librosa"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.6/dist-packages (0.6.3)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (2.1.6)\n",
            "Requirement already satisfied: numpy>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.14.6)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.20.3)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.12.5)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (4.4.0)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.11.0)\n",
            "Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.2.1)\n",
            "Requirement already satisfied: numba>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.40.1)\n",
            "Requirement already satisfied: llvmlite>=0.25.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa) (0.28.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "K9ebAduRaHmw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QPVprwLbaQHf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LiNjwAkyaSVT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6tlbO-UyaXuQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trx = []\n",
        "trs = []\n",
        "trn = []\n",
        "\n",
        "trx_val = []\n",
        "trs_val = []\n",
        "trn_val = []\n",
        "target = []\n",
        "\n",
        "trx_len = []\n",
        "\n",
        "max_width = 513\n",
        "max_length = 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qgxzwr6iHIBx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6f908ce6-ac44-4a8d-dd34-062b2085a748"
      },
      "cell_type": "code",
      "source": [
        "# check if pickle files exist\n",
        "pickle_paths = ['trx.pickle', 'trs.pickle', 'trn.pickle', 'trx_val.pickle', \\\n",
        "                'trs_val.pickle', 'trn_val.pickle', 'target.pickle', \n",
        "                'trx_len.pickle', 'trx_id.pickle']\n",
        "found_saved = all([os.path.exists(base_path_pickle + x) for x in pickle_paths])\n",
        "found_saved"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "6EXkf920G8g0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if found_saved:\n",
        "  with open(base_path_pickle + 'trx.pickle', 'rb') as f:\n",
        "    trx = pickle.load(f)\n",
        "  with open(base_path_pickle + 'trs.pickle', 'rb') as f:\n",
        "    trs = pickle.load(f)\n",
        "  with open(base_path_pickle + 'trn.pickle', 'rb') as f:\n",
        "    trn = pickle.load(f)\n",
        "  with open(base_path_pickle + 'trx_val.pickle', 'rb') as f:\n",
        "    trx_val = pickle.load(f)\n",
        "  with open(base_path_pickle + 'trs_val.pickle', 'rb') as f:\n",
        "    trs_val = pickle.load(f)\n",
        "  with open(base_path_pickle + 'trn_val.pickle', 'rb') as f:\n",
        "    trn_val = pickle.load(f)\n",
        "  with open(base_path_pickle + 'target.pickle', 'rb') as f:\n",
        "    target = pickle.load(f)\n",
        "  with open(base_path_pickle + 'trx_len.pickle', 'rb') as f:\n",
        "    trx_len = pickle.load(f)\n",
        "  with open(base_path_pickle + 'trx_id.pickle', 'rb') as f:\n",
        "    trx_id = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5zHGEhInJQIa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_stft(file_path):\n",
        "  s, sr = librosa.load(file_path, sr=None)\n",
        "  stft = librosa.stft(s, n_fft=1024, hop_length=512).T\n",
        "  stft_val = np.zeros((max_length, max_width))\n",
        "  stft_val[:stft.shape[0], :stft.shape[1]] = np.abs(stft)\n",
        "  return stft, stft_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Onxg0kmxKzKV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_from_directory(directory, file_prefix, all_required):\n",
        "  file_prefix_dirty = file_prefix + 'x'\n",
        "  file_prefix_clean = file_prefix + 's'\n",
        "  file_prefix_noise = file_prefix + 'n'\n",
        "  \n",
        "  lfd_x = []\n",
        "  lfd_s = []\n",
        "  lfd_n = []\n",
        "  \n",
        "  lfd_x_val = []\n",
        "  lfd_s_val = []\n",
        "  lfd_n_val = []\n",
        "  \n",
        "  lfd_target = []\n",
        "  lfd_len = []\n",
        "  lfd_id = []\n",
        "  \n",
        "  n = 0\n",
        "  for file in sorted(os.listdir(directory)):\n",
        "    # consider only .wav files starting with file_prefix_dirty\n",
        "    if file.endswith('.wav') and file.startswith(file_prefix_dirty):\n",
        "      if n == 20:\n",
        "        break\n",
        "      n += 1\n",
        "      \n",
        "      file_id = file[len(file_prefix_dirty):-len('.wav')]\n",
        "\n",
        "      dirty_file_path = os.path.join(directory, file)\n",
        "\n",
        "      if all_required:\n",
        "        # check if there is corresponding target/clean file\n",
        "        clean_file_name = file.replace(file_prefix_dirty, file_prefix_clean)\n",
        "        clean_file_path = os.path.join(directory, clean_file_name)\n",
        "        if not os.path.exists(clean_file_path):\n",
        "          continue\n",
        "\n",
        "        noise_file_name = file.replace(file_prefix_dirty, file_prefix_noise)\n",
        "        noise_file_path = os.path.join(directory, noise_file_name)\n",
        "        if not os.path.exists(clean_file_path):\n",
        "          continue\n",
        "\n",
        "      # load both dirty, clean and noise files\n",
        "      train_dirty, train_dirty_val = get_stft(dirty_file_path)\n",
        "      if all_required:\n",
        "        train_clean, train_clean_val = get_stft(clean_file_path)\n",
        "        train_noise, train_noise_val = get_stft(noise_file_path)\n",
        "      \n",
        "      lfd_x.append(train_dirty)\n",
        "      lfd_len.append(len(train_dirty))\n",
        "      lfd_id.append(file_id)\n",
        "      \n",
        "      if all_required:\n",
        "        lfd_s.append(train_clean)\n",
        "        lfd_n.append(train_noise)\n",
        "\n",
        "      lfd_x_val.append(train_dirty_val)\n",
        "      if all_required:\n",
        "        lfd_s_val.append(train_clean_val)\n",
        "        lfd_n_val.append(train_noise_val)\n",
        "\n",
        "      if all_required:\n",
        "        # multiply by 1 to convert boolean to integer\n",
        "        lfd_target.append(1 * (train_clean_val > train_noise_val)) \n",
        "        \n",
        "  if all_required:\n",
        "    return lfd_x, lfd_s, lfd_n, np.array(lfd_x_val), np.array(lfd_s_val), \\\n",
        "                                np.array(lfd_n_val), np.array(lfd_target), \\\n",
        "                                np.array(lfd_len), np.array(lfd_id)\n",
        "  return lfd_x, np.array(lfd_x_val), np.array(lfd_len), np.array(lfd_id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vsCzFQmBG6Mr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if not found_saved:\n",
        "  trx, trs, trn, trx_val, trs_val, trn_val, target, trx_len, trx_id = load_from_directory(base_path_train, \\\n",
        "                                                                        'tr', True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MOYN0aNFIC6t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e3ea3865-c912-4be5-9e18-3558af7d8cbc"
      },
      "cell_type": "code",
      "source": [
        "trx_val.shape, trs_val.shape, trn_val.shape, target.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((20, 200, 513), (20, 200, 513), (20, 200, 513), (20, 200, 513))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "WUYy0xAGvbrU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "187a0c0b-9775-4ec4-c2d1-1e7fbb7e6306"
      },
      "cell_type": "code",
      "source": [
        "trx_id"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['0000', '0001', '0002', '0003', '0004', '0005', '0006', '0007',\n",
              "       '0008', '0009', '0010', '0011', '0012', '0013', '0014', '0015',\n",
              "       '0016', '0017', '0018', '0019'], dtype='<U4')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "yHvqjNJ3DUG0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if not found_saved:\n",
        "  with open(base_path_pickle + 'trx.pickle', 'wb') as f:\n",
        "    pickle.dump(trx, f)\n",
        "  with open(base_path_pickle + 'trs.pickle', 'wb') as f:\n",
        "    pickle.dump(trs, f)\n",
        "  with open(base_path_pickle + 'trn.pickle', 'wb') as f:\n",
        "    pickle.dump(trn, f)\n",
        "  with open(base_path_pickle + 'trx_val.pickle', 'wb') as f:\n",
        "    pickle.dump(trx_val, f)\n",
        "  with open(base_path_pickle + 'trs_val.pickle', 'wb') as f:\n",
        "    pickle.dump(trs_val, f)\n",
        "  with open(base_path_pickle + 'trn_val.pickle', 'wb') as f:\n",
        "    pickle.dump(trn_val, f)\n",
        "  with open(base_path_pickle + 'target.pickle', 'wb') as f:\n",
        "    pickle.dump(target, f)\n",
        "  with open(base_path_pickle + 'trx_len.pickle', 'wb') as f:\n",
        "    pickle.dump(trx_len, f)\n",
        "  with open(base_path_pickle + 'trx_id.pickle', 'wb') as f:\n",
        "    pickle.dump(trx_len, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WY6p8_VpFRHr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fputklBJwsHG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_samples_tr = len(trx_val)\n",
        "batch_size = 10\n",
        "num_features = 513\n",
        "num_hidden = 256\n",
        "\n",
        "learning_rate = 0.001\n",
        "num_epochs = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vn5eY0P5wiD_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = tf.placeholder(tf.float32, [None, max_length, num_features])\n",
        "Y = tf.placeholder(tf.float32, [None, max_length, num_features])\n",
        "# xlen = tf.placeholder(tf.int32, None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B5pMHqkXv2gd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "98aefd38-796e-48b8-8812-b958e048ff33"
      },
      "cell_type": "code",
      "source": [
        "cell = tf.nn.rnn_cell.DropoutWrapper(tf.nn.rnn_cell.LSTMCell(num_hidden))\n",
        "output, state = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
        "dense_1 = tf.layers.Dense(units=513, activation=tf.nn.sigmoid)(output)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-18-2c52f2eb71f4>:1: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-18-2c52f2eb71f4>:2: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/tensor_array_ops.py:162: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JFbPl1Bm_cl7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3f4aa3d9-8006-480c-c504-97faf4428984"
      },
      "cell_type": "code",
      "source": [
        "dense_1"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'dense/Sigmoid:0' shape=(?, 200, 513) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "7pKn5pH1uwNa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "355ac52c-af85-4317-bb5c-f5de8c70324d"
      },
      "cell_type": "code",
      "source": [
        "# calculate loss - only calculate loss on valid data\n",
        "loss = tf.losses.mean_squared_error(labels=Y, predictions=dense_1)\n",
        "train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss=loss)\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:667: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "O8VvjQOBy5Sp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess = tf.Session()\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yflR2Gr6zBRL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "6952b77f-3fcb-480d-9ede-43d8027a2a1c"
      },
      "cell_type": "code",
      "source": [
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  loss_val = 0\n",
        "  for i in range(0, num_samples_tr, batch_size):\n",
        "    start_idx = i\n",
        "    end_idx = min(i + batch_size, num_samples_tr)\n",
        "    \n",
        "    batch_x = trx_val[start_idx:end_idx]\n",
        "    batch_y = target[start_idx:end_idx]\n",
        "    \n",
        "    _, lv = sess.run([train, loss], feed_dict={X: batch_x, Y: batch_y})\n",
        "    loss_val += lv\n",
        "  print(epoch, loss_val)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.4987002909183502\n",
            "1 0.4883114695549011\n",
            "2 0.4610311836004257\n",
            "3 0.3720315247774124\n",
            "4 0.31802573800086975\n",
            "5 0.29188916087150574\n",
            "6 0.28080742061138153\n",
            "7 0.27705690264701843\n",
            "8 0.27426961809396744\n",
            "9 0.2700883001089096\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eIOydmwQBHfU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def clean(X, M, filename):\n",
        "  cleaned = X * M\n",
        "  sh_test = librosa.istft(cleaned.T, hop_length=512)\n",
        "    \n",
        "  # Save to a file\n",
        "  librosa.output.write_wav(filename, sh_test, 16000)\n",
        "  print('Saved to ', filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XBPRMds_CL7o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tex, tex_val, tex_len, tex_id = load_from_directory(base_path_test, 'te', False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E5bXZQbGZHdQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "c7a90632-5ac6-435d-f43d-1637dc3003dc"
      },
      "cell_type": "code",
      "source": [
        "num_samples_te = len(tex_val)\n",
        "\n",
        "for i in range(0, num_samples_te, batch_size):\n",
        "  start_idx = i\n",
        "  end_idx = min(i + batch_size, num_samples_te)\n",
        "  \n",
        "  batch_x = tex_val[start_idx:end_idx]\n",
        "\n",
        "  m_pred = sess.run([dense_1], feed_dict={X: batch_x})\n",
        "  for j in range(start_idx, end_idx):\n",
        "    x = tex[j]\n",
        "    m = m_pred[0][i - start_idx][:tex_len[j], :]\n",
        "    fname = base_path_result + 'cleaned' + tex_id[j] + '.wav'\n",
        "    \n",
        "    clean(x, m, fname)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved to  ./drive/My Drive/Colab Notebooks/Speech Denoising/LotOfData/result/cleaned0000.wav\n",
            "Saved to  ./drive/My Drive/Colab Notebooks/Speech Denoising/LotOfData/result/cleaned0001.wav\n",
            "Saved to  ./drive/My Drive/Colab Notebooks/Speech Denoising/LotOfData/result/cleaned0002.wav\n",
            "Saved to  ./drive/My Drive/Colab Notebooks/Speech Denoising/LotOfData/result/cleaned0003.wav\n",
            "Saved to  ./drive/My Drive/Colab Notebooks/Speech Denoising/LotOfData/result/cleaned0004.wav\n",
            "Saved to  ./drive/My Drive/Colab Notebooks/Speech Denoising/LotOfData/result/cleaned0005.wav\n",
            "Saved to  ./drive/My Drive/Colab Notebooks/Speech Denoising/LotOfData/result/cleaned0006.wav\n",
            "Saved to  ./drive/My Drive/Colab Notebooks/Speech Denoising/LotOfData/result/cleaned0007.wav\n",
            "Saved to  ./drive/My Drive/Colab Notebooks/Speech Denoising/LotOfData/result/cleaned0008.wav\n",
            "Saved to  ./drive/My Drive/Colab Notebooks/Speech Denoising/LotOfData/result/cleaned0009.wav\n",
            "Saved to  ./drive/My Drive/Colab Notebooks/Speech Denoising/LotOfData/result/cleaned0010.wav\n",
            "Saved to  ./drive/My Drive/Colab Notebooks/Speech Denoising/LotOfData/result/cleaned0011.wav\n",
            "Saved to  ./drive/My Drive/Colab Notebooks/Speech Denoising/LotOfData/result/cleaned0012.wav\n",
            "Saved to  ./drive/My Drive/Colab Notebooks/Speech Denoising/LotOfData/result/cleaned0013.wav\n",
            "Saved to  ./drive/My Drive/Colab Notebooks/Speech Denoising/LotOfData/result/cleaned0014.wav\n",
            "Saved to  ./drive/My Drive/Colab Notebooks/Speech Denoising/LotOfData/result/cleaned0015.wav\n",
            "Saved to  ./drive/My Drive/Colab Notebooks/Speech Denoising/LotOfData/result/cleaned0016.wav\n",
            "Saved to  ./drive/My Drive/Colab Notebooks/Speech Denoising/LotOfData/result/cleaned0017.wav\n",
            "Saved to  ./drive/My Drive/Colab Notebooks/Speech Denoising/LotOfData/result/cleaned0018.wav\n",
            "Saved to  ./drive/My Drive/Colab Notebooks/Speech Denoising/LotOfData/result/cleaned0019.wav\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lutKogegAtLd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}