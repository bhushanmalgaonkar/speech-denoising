{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "speech-denoising-using-lstm.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "TRJwZmWFZVUH",
        "colab_type": "code",
        "outputId": "aa7071f9-8eda-45be-983a-f6ec4a236fed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bBe8sG2ZaCm1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "base_path = './drive/My Drive/Colab Notebooks/Speech Denoising/LotOfData/'\n",
        "\n",
        "base_path_train = base_path + 'tr/'\n",
        "base_path_val = base_path + 'v/'\n",
        "base_path_test = base_path + 'te/'\n",
        "\n",
        "base_path_pickle = base_path + 'pickle/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VVGaYrEfaEWU",
        "colab_type": "code",
        "outputId": "e1e2bd04-a59b-43da-ddae-ff4db2e6655e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install librosa"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.6/dist-packages (0.6.3)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (2.1.6)\n",
            "Requirement already satisfied: numpy>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.14.6)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.20.3)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.12.5)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (4.4.0)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.11.0)\n",
            "Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.2.1)\n",
            "Requirement already satisfied: numba>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.40.1)\n",
            "Requirement already satisfied: llvmlite>=0.25.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa) (0.28.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "K9ebAduRaHmw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QPVprwLbaQHf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LiNjwAkyaSVT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6tlbO-UyaXuQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trx = []\n",
        "trs = []\n",
        "trn = []\n",
        "\n",
        "trx_val = []\n",
        "trs_val = []\n",
        "trn_val = []\n",
        "target = []\n",
        "\n",
        "max_width = 513\n",
        "max_length = 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qgxzwr6iHIBx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ccdc4e77-c2cb-4d2f-9775-3ec88f8b8c20"
      },
      "cell_type": "code",
      "source": [
        "# check if pickle files exist\n",
        "pickle_paths = ['trx.pickle', 'trs.pickle', 'trn.pickle', 'trx_val.pickle', 'trs_val.pickle', 'trn_val.pickle', 'target.pickle']\n",
        "found_saved = all([os.path.exists(base_path_pickle + x) for x in pickle_paths])\n",
        "found_saved"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "6EXkf920G8g0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if found_saved:\n",
        "  with open(base_path_pickle + 'trx.pickle', 'rb') as f:\n",
        "    trx = pickle.load(f)\n",
        "  with open(base_path_pickle + 'trs.pickle', 'rb') as f:\n",
        "    trs = pickle.load(f)\n",
        "  with open(base_path_pickle + 'trn.pickle', 'rb') as f:\n",
        "    trn = pickle.load(f)\n",
        "  with open(base_path_pickle + 'trx_val.pickle', 'rb') as f:\n",
        "    trx_val = pickle.load(f)\n",
        "  with open(base_path_pickle + 'trs_val.pickle', 'rb') as f:\n",
        "    trs_val = pickle.load(f)\n",
        "  with open(base_path_pickle + 'trn_val.pickle', 'rb') as f:\n",
        "    trn_val = pickle.load(f)\n",
        "  with open(base_path_pickle + 'target.pickle', 'rb') as f:\n",
        "    target = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vsCzFQmBG6Mr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if not found_saved:\n",
        "  n = 0\n",
        "  for file in sorted(os.listdir(base_path_train)):\n",
        "    # consider only .wav files starting with trx\n",
        "    if file.endswith('.wav') and file.startswith('trx'):\n",
        "      if n == 20:\n",
        "        break\n",
        "      n += 1\n",
        "\n",
        "      dirty_file_path = os.path.join(base_path_train, file)\n",
        "\n",
        "      # check if there is corresponding target/clean file\n",
        "      clean_file_name = file.replace('trx', 'trs')\n",
        "      clean_file_path = os.path.join(base_path_train, clean_file_name)\n",
        "      if not os.path.exists(clean_file_path):\n",
        "        continue\n",
        "\n",
        "      noise_file_name = file.replace('trx', 'trn')\n",
        "      noise_file_path = os.path.join(base_path_train, noise_file_name)\n",
        "      if not os.path.exists(clean_file_path):\n",
        "        continue\n",
        "\n",
        "      # load both dirty, clean and noise files\n",
        "      s, sr = librosa.load(dirty_file_path, sr=None)\n",
        "      train_dirty = librosa.stft(s, n_fft=1024, hop_length=512).T\n",
        "      train_dirty_val = np.zeros((max_length, max_width))\n",
        "      train_dirty_val[:train_dirty.shape[0], :train_dirty.shape[1]] = np.abs(train_dirty)\n",
        "\n",
        "      s, sr = librosa.load(clean_file_path, sr=None)\n",
        "      train_clean = librosa.stft(s, n_fft=1024, hop_length=512).T\n",
        "      train_clean_val = np.zeros((max_length, max_width))\n",
        "      train_clean_val[:train_clean.shape[0], :train_clean.shape[1]] = np.abs(train_clean)\n",
        "\n",
        "      s, sr = librosa.load(noise_file_path, sr=None)\n",
        "      train_noise = librosa.stft(s, n_fft=1024, hop_length=512).T\n",
        "      train_noise_val = np.zeros((max_length, max_width))\n",
        "      train_noise_val[:train_noise.shape[0], :train_noise.shape[1]] = np.abs(train_noise)\n",
        "\n",
        "      trx.append(train_dirty)\n",
        "      trs.append(train_clean)\n",
        "  #     trn.append(train_noise)\n",
        "\n",
        "      trx_val.append(train_dirty_val)\n",
        "      trs_val.append(train_clean_val)\n",
        "  #     trn_val.append(train_noise_val)\n",
        "\n",
        "      target.append(1 * (train_clean_val > train_noise_val)) # multiply by 1 to convert boolean to integer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cNHHcG3QizPf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if not found_saved:\n",
        "  trx_val = np.array(trx_val)\n",
        "  trs_val = np.array(trx_val)\n",
        "  trn_val = np.array(trn_val)\n",
        "  target = np.array(target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MOYN0aNFIC6t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "07d4adfd-c3e1-4c96-8b3a-2c03e01d0212"
      },
      "cell_type": "code",
      "source": [
        "trx_val.shape, trs_val.shape, trn_val.shape, target.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((20, 200, 513), (20, 200, 513), (0,), (20, 200, 513))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "yHvqjNJ3DUG0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if not found_saved:\n",
        "  with open(base_path_pickle + 'trx.pickle', 'wb') as f:\n",
        "    pickle.dump(trx, f)\n",
        "  with open(base_path_pickle + 'trs.pickle', 'wb') as f:\n",
        "    pickle.dump(trs, f)\n",
        "  with open(base_path_pickle + 'trn.pickle', 'wb') as f:\n",
        "    pickle.dump(trn, f)\n",
        "  with open(base_path_pickle + 'trx_val.pickle', 'wb') as f:\n",
        "    pickle.dump(trx_val, f)\n",
        "  with open(base_path_pickle + 'trs_val.pickle', 'wb') as f:\n",
        "    pickle.dump(trs_val, f)\n",
        "  with open(base_path_pickle + 'trn_val.pickle', 'wb') as f:\n",
        "    pickle.dump(trn_val, f)\n",
        "  with open(base_path_pickle + 'target.pickle', 'wb') as f:\n",
        "    pickle.dump(target, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WY6p8_VpFRHr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fputklBJwsHG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_samples = len(trx_val)\n",
        "batch_size = 10\n",
        "num_features = 513\n",
        "num_hidden = 256\n",
        "\n",
        "learning_rate = 0.001\n",
        "num_epochs = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vn5eY0P5wiD_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = tf.placeholder(tf.float32, [None, max_length, num_features])\n",
        "Y = tf.placeholder(tf.float32, [None, max_length, num_features])\n",
        "seqlen = tf.placeholder(tf.int32, None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B5pMHqkXv2gd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "76a3f4f2-c382-4784-888f-474400dd686d"
      },
      "cell_type": "code",
      "source": [
        "cell = tf.nn.rnn_cell.DropoutWrapper(tf.nn.rnn_cell.LSTMCell(num_hidden))\n",
        "output, state = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-16-d25a40204e65>:1: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-16-d25a40204e65>:2: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/tensor_array_ops.py:162: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bTLW7eFbl7GT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dense_1 = tf.layers.Dense(units=513, activation=tf.nn.sigmoid)(output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7pKn5pH1uwNa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b6200d4b-6e5f-4d54-9fcc-588cd69642f4"
      },
      "cell_type": "code",
      "source": [
        "# calculate loss\n",
        "loss = tf.losses.mean_squared_error(labels=Y, predictions=dense_1)\n",
        "train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss=loss)\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:667: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "O8VvjQOBy5Sp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess = tf.Session()\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yflR2Gr6zBRL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "21111b1a-7a71-469d-e502-3abade183bbe"
      },
      "cell_type": "code",
      "source": [
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  loss_val = 0\n",
        "  for i in range(0, num_samples, batch_size):\n",
        "    start_idx = i\n",
        "    end_idx = min(i + batch_size, num_samples)\n",
        "    \n",
        "    batch_x = trx_val[start_idx:end_idx]\n",
        "    batch_y = target[start_idx:end_idx]\n",
        "    \n",
        "    _, lv = sess.run([train, loss], feed_dict={X: batch_x, Y: batch_y})\n",
        "    loss_val += lv\n",
        "  print(i, loss_val)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 0.49871134757995605\n",
            "10 0.48774541914463043\n",
            "10 0.4548940658569336\n",
            "10 0.3625613749027252\n",
            "10 0.3137256056070328\n",
            "10 0.2897723615169525\n",
            "10 0.2798348739743233\n",
            "10 0.27602875977754593\n",
            "10 0.2725963816046715\n",
            "10 0.2675434648990631\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XBPRMds_CL7o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}