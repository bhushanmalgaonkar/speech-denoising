{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "speech-denoising-using-lstm.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "TRJwZmWFZVUH",
        "colab_type": "code",
        "outputId": "8cfefa95-bfee-4b33-82d9-4a4488838561",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bBe8sG2ZaCm1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "base_path = './drive/My Drive/Colab Notebooks/Speech Denoising/LotOfData/'\n",
        "\n",
        "base_path_train = base_path + 'tr/'\n",
        "base_path_val = base_path + 'v/'\n",
        "base_path_test = base_path + 'te/'\n",
        "\n",
        "base_path_pickle = base_path + 'pickle/'\n",
        "\n",
        "base_path_result = base_path + 'result/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VVGaYrEfaEWU",
        "colab_type": "code",
        "outputId": "fd815c23-fa9b-43c4-a767-dee742ad646a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install librosa"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.6/dist-packages (0.6.3)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (2.1.6)\n",
            "Requirement already satisfied: numpy>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.14.6)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.20.3)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.12.5)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (4.4.0)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.11.0)\n",
            "Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.2.1)\n",
            "Requirement already satisfied: numba>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.40.1)\n",
            "Requirement already satisfied: llvmlite>=0.25.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa) (0.28.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "K9ebAduRaHmw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QPVprwLbaQHf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LiNjwAkyaSVT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6tlbO-UyaXuQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trx = []\n",
        "trs = []\n",
        "trn = []\n",
        "\n",
        "trx_val = []\n",
        "trs_val = []\n",
        "trn_val = []\n",
        "target = []\n",
        "\n",
        "trx_len = []\n",
        "\n",
        "max_width = 513\n",
        "max_length = 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qgxzwr6iHIBx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "280e9b2a-7065-4f5a-aede-074e9fa69a5c"
      },
      "cell_type": "code",
      "source": [
        "# check if pickle files exist\n",
        "pickle_paths = ['trx.pickle', 'trs.pickle', 'trn.pickle', 'trx_val.pickle', \\\n",
        "                'trs_val.pickle', 'trn_val.pickle', 'target.pickle', \n",
        "                'trx_len.pickle', 'trx_id.pickle']\n",
        "found_saved = all([os.path.exists(base_path_pickle + x) for x in pickle_paths])\n",
        "found_saved"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "6EXkf920G8g0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if found_saved:\n",
        "  with open(base_path_pickle + 'trx.pickle', 'rb') as f:\n",
        "    trx = pickle.load(f)\n",
        "  with open(base_path_pickle + 'trs.pickle', 'rb') as f:\n",
        "    trs = pickle.load(f)\n",
        "  with open(base_path_pickle + 'trn.pickle', 'rb') as f:\n",
        "    trn = pickle.load(f)\n",
        "  with open(base_path_pickle + 'trx_val.pickle', 'rb') as f:\n",
        "    trx_val = pickle.load(f)\n",
        "  with open(base_path_pickle + 'trs_val.pickle', 'rb') as f:\n",
        "    trs_val = pickle.load(f)\n",
        "  with open(base_path_pickle + 'trn_val.pickle', 'rb') as f:\n",
        "    trn_val = pickle.load(f)\n",
        "  with open(base_path_pickle + 'target.pickle', 'rb') as f:\n",
        "    target = pickle.load(f)\n",
        "  with open(base_path_pickle + 'trx_len.pickle', 'rb') as f:\n",
        "    trx_len = pickle.load(f)\n",
        "  with open(base_path_pickle + 'trx_id.pickle', 'rb') as f:\n",
        "    trx_id = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5zHGEhInJQIa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_stft(file_path):\n",
        "  s, sr = librosa.load(file_path, sr=None)\n",
        "  stft = librosa.stft(s, n_fft=1024, hop_length=512).T\n",
        "  stft_val = np.zeros((max_length, max_width))\n",
        "  stft_val[:stft.shape[0], :stft.shape[1]] = np.abs(stft)\n",
        "  return stft, stft_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Onxg0kmxKzKV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_from_directory(directory, file_prefix, all_required):\n",
        "  file_prefix_dirty = file_prefix + 'x'\n",
        "  file_prefix_clean = file_prefix + 's'\n",
        "  file_prefix_noise = file_prefix + 'n'\n",
        "  \n",
        "  lfd_x = []\n",
        "  lfd_s = []\n",
        "  lfd_n = []\n",
        "  \n",
        "  lfd_x_val = []\n",
        "  lfd_s_val = []\n",
        "  lfd_n_val = []\n",
        "  \n",
        "  lfd_target = []\n",
        "  lfd_len = []\n",
        "  lfd_id = []\n",
        "  \n",
        "  n = 0\n",
        "  for file in sorted(os.listdir(directory)):\n",
        "    # consider only .wav files starting with file_prefix_dirty\n",
        "    if file.endswith('.wav') and file.startswith(file_prefix_dirty):\n",
        "#       if n == 20:\n",
        "#         break\n",
        "#       n += 1\n",
        "      \n",
        "      file_id = file[len(file_prefix_dirty):-len('.wav')]\n",
        "\n",
        "      dirty_file_path = os.path.join(directory, file)\n",
        "\n",
        "      if all_required:\n",
        "        # check if there is corresponding target/clean file\n",
        "        clean_file_name = file.replace(file_prefix_dirty, file_prefix_clean)\n",
        "        clean_file_path = os.path.join(directory, clean_file_name)\n",
        "        if not os.path.exists(clean_file_path):\n",
        "          continue\n",
        "\n",
        "        noise_file_name = file.replace(file_prefix_dirty, file_prefix_noise)\n",
        "        noise_file_path = os.path.join(directory, noise_file_name)\n",
        "        if not os.path.exists(clean_file_path):\n",
        "          continue\n",
        "\n",
        "      # load both dirty, clean and noise files\n",
        "      train_dirty, train_dirty_val = get_stft(dirty_file_path)\n",
        "      if all_required:\n",
        "        train_clean, train_clean_val = get_stft(clean_file_path)\n",
        "        train_noise, train_noise_val = get_stft(noise_file_path)\n",
        "      \n",
        "      lfd_x.append(train_dirty)\n",
        "      lfd_len.append(len(train_dirty))\n",
        "      lfd_id.append(file_id)\n",
        "      \n",
        "      if all_required:\n",
        "        lfd_s.append(train_clean)\n",
        "        lfd_n.append(train_noise)\n",
        "\n",
        "      lfd_x_val.append(train_dirty_val)\n",
        "      if all_required:\n",
        "        lfd_s_val.append(train_clean_val)\n",
        "        lfd_n_val.append(train_noise_val)\n",
        "\n",
        "      if all_required:\n",
        "        # multiply by 1 to convert boolean to integer\n",
        "        lfd_target.append(1 * (train_clean_val > train_noise_val)) \n",
        "        \n",
        "  if all_required:\n",
        "    return lfd_x, lfd_s, lfd_n, np.array(lfd_x_val), np.array(lfd_s_val), \\\n",
        "                                np.array(lfd_n_val), np.array(lfd_target), \\\n",
        "                                np.array(lfd_len), np.array(lfd_id)\n",
        "  return lfd_x, np.array(lfd_x_val), np.array(lfd_len), np.array(lfd_id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vsCzFQmBG6Mr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if not found_saved:\n",
        "  trx, trs, trn, trx_val, trs_val, trn_val, target, trx_len, trx_id = load_from_directory(base_path_train, \\\n",
        "                                                                        'tr', True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MOYN0aNFIC6t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "87273906-112a-43b7-c959-59234ea551a2"
      },
      "cell_type": "code",
      "source": [
        "trx_val.shape, trs_val.shape, trn_val.shape, target.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1200, 200, 513), (1200, 200, 513), (1200, 200, 513), (1200, 200, 513))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "WUYy0xAGvbrU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ba093d57-fcad-427e-ae87-a1dbdae0b606"
      },
      "cell_type": "code",
      "source": [
        "trx_id"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['0000', '0001', '0002', ..., '1197', '1198', '1199'], dtype='<U4')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "yHvqjNJ3DUG0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if not found_saved:\n",
        "  with open(base_path_pickle + 'trx.pickle', 'wb') as f:\n",
        "    pickle.dump(trx, f)\n",
        "  with open(base_path_pickle + 'trs.pickle', 'wb') as f:\n",
        "    pickle.dump(trs, f)\n",
        "  with open(base_path_pickle + 'trn.pickle', 'wb') as f:\n",
        "    pickle.dump(trn, f)\n",
        "  with open(base_path_pickle + 'trx_val.pickle', 'wb') as f:\n",
        "    pickle.dump(trx_val, f)\n",
        "  with open(base_path_pickle + 'trs_val.pickle', 'wb') as f:\n",
        "    pickle.dump(trs_val, f)\n",
        "  with open(base_path_pickle + 'trn_val.pickle', 'wb') as f:\n",
        "    pickle.dump(trn_val, f)\n",
        "  with open(base_path_pickle + 'target.pickle', 'wb') as f:\n",
        "    pickle.dump(target, f)\n",
        "  with open(base_path_pickle + 'trx_len.pickle', 'wb') as f:\n",
        "    pickle.dump(trx_len, f)\n",
        "  with open(base_path_pickle + 'trx_id.pickle', 'wb') as f:\n",
        "    pickle.dump(trx_len, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WY6p8_VpFRHr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fputklBJwsHG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_samples_tr = len(trx_val)\n",
        "batch_size = 20\n",
        "num_features = 513\n",
        "num_hidden = 256\n",
        "\n",
        "learning_rate = 0.001\n",
        "num_epochs = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vn5eY0P5wiD_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = tf.placeholder(tf.float32, [None, max_length, num_features])\n",
        "Y = tf.placeholder(tf.float32, [None, max_length, num_features])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B5pMHqkXv2gd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "56df0ab3-2eb6-48ca-ca6e-0690b524c055"
      },
      "cell_type": "code",
      "source": [
        "cell = tf.nn.rnn_cell.DropoutWrapper(tf.nn.rnn_cell.LSTMCell(num_hidden))\n",
        "output, state = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
        "dense_1 = tf.layers.Dense(units=513, activation=tf.nn.sigmoid)(output)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-18-2c52f2eb71f4>:1: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-18-2c52f2eb71f4>:2: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/tensor_array_ops.py:162: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JFbPl1Bm_cl7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5b9b6ea9-19db-4236-9c7e-ffb8be4045ac"
      },
      "cell_type": "code",
      "source": [
        "dense_1"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'dense/Sigmoid:0' shape=(?, 200, 513) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "7pKn5pH1uwNa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d7f4448c-ae05-42a6-d66a-1c0b3b7afbb5"
      },
      "cell_type": "code",
      "source": [
        "# calculate loss - only calculate loss on valid data\n",
        "loss = tf.losses.mean_squared_error(labels=Y, predictions=dense_1)\n",
        "train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss=loss)\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:667: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "O8VvjQOBy5Sp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess = tf.Session()\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yflR2Gr6zBRL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 945
        },
        "outputId": "1c6323f7-bdad-4d85-9bd4-2076b047b239"
      },
      "cell_type": "code",
      "source": [
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  loss_val = 0\n",
        "  for i in range(0, num_samples_tr, batch_size):\n",
        "    start_idx = i\n",
        "    end_idx = min(i + batch_size, num_samples_tr)\n",
        "    \n",
        "    batch_x = trx_val[start_idx:end_idx]\n",
        "    batch_y = target[start_idx:end_idx]\n",
        "    \n",
        "    _, lv = sess.run([train, loss], feed_dict={X: batch_x, Y: batch_y})\n",
        "    loss_val += lv\n",
        "    \n",
        "  if epoch % 10 == 9:\n",
        "    print(epoch, loss_val)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-58abea8d62ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mloss_val\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "3Qo4bJXIe3WK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def snr(dirty, clean):\n",
        "  return 10 * np.log10(np.sum(np.square(clean))/np.sum(np.square(clean - dirty)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eIOydmwQBHfU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def save(cleaned, filename):\n",
        "  sh_test = librosa.istft(cleaned.T, hop_length=512)\n",
        "    \n",
        "  # Save to a file\n",
        "  librosa.output.write_wav(filename, sh_test, 16000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "twG9y6_2k-_L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# check if pickle files exist\n",
        "pickle_paths = ['vx.pickle', 'vs.pickle', 'vn.pickle', 'vx_val.pickle', \\\n",
        "                'vs_val.pickle', 'vn_val.pickle', 'target_v.pickle', \n",
        "                'vx_len.pickle', 'vx_id.pickle']\n",
        "found_saved = all([os.path.exists(base_path_pickle + x) for x in pickle_paths])\n",
        "\n",
        "if not found_saved:\n",
        "  vx, vs, vn, vx_val, vs_val, vn_val, target, vx_len, vx_id = load_from_directory(base_path_val, \\\n",
        "                                                                        'v', True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wHaMGNsck06-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_samples_v = len(vx_val)\n",
        "\n",
        "total_snr = 0\n",
        "for i in range(0, num_samples_v, batch_size):\n",
        "  start_idx = i\n",
        "  end_idx = min(i + batch_size, num_samples_v)\n",
        "  \n",
        "  batch_x = tex_val[start_idx:end_idx]\n",
        "\n",
        "  m_pred = sess.run([dense_1], feed_dict={X: batch_x})\n",
        "  for j in range(start_idx, end_idx):\n",
        "    x = vx[j]\n",
        "    s = vx_val[j][:vx_len[j], :]\n",
        "    m = m_pred[0][i - start_idx][:vx_len[j], :]\n",
        "    \n",
        "    cleaned = x * m\n",
        "    fname = base_path_result + 'cleaned' + vx_id[j] + '.wav'\n",
        "    \n",
        "#     save(x * m, fname)\n",
        "    total_snr += snr(s, np.abs(cleaned))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XBPRMds_CL7o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tex, tex_val, tex_len, tex_id = load_from_directory(base_path_test, 'te', False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E5bXZQbGZHdQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_samples_te = len(tex_val)\n",
        "\n",
        "total_snr = 0\n",
        "for i in range(0, num_samples_te, batch_size):\n",
        "  start_idx = i\n",
        "  end_idx = min(i + batch_size, num_samples_te)\n",
        "  \n",
        "  batch_x = tex_val[start_idx:end_idx]\n",
        "\n",
        "  m_pred = sess.run([dense_1], feed_dict={X: batch_x})\n",
        "  for j in range(start_idx, end_idx):\n",
        "    x = tex[j]\n",
        "    s = tex_val[j][:tex_len[j], :]\n",
        "    m = m_pred[0][i - start_idx][:tex_len[j], :]\n",
        "    \n",
        "    cleaned = x * m\n",
        "    fname = base_path_result + 'cleaned' + tex_id[j] + '.wav'\n",
        "    \n",
        "#     save(x * m, fname)\n",
        "    total_snr += snr(s, np.abs(cleaned))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lutKogegAtLd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a612382d-af40-4c67-b086-eaf20fcb4242"
      },
      "cell_type": "code",
      "source": [
        "total_snr/num_samples_te"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-18.202732053582743"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "metadata": {
        "id": "XQ1IrleJjXNp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}