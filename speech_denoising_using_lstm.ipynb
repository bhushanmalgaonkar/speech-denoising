{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "speech-denoising-using-lstm.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "TRJwZmWFZVUH",
        "colab_type": "code",
        "outputId": "a4e754c2-6f23-4e62-c115-3002690f5cc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bBe8sG2ZaCm1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "base_path = './drive/My Drive/Colab Notebooks/Speech Denoising/LotOfData/'\n",
        "\n",
        "base_path_train = base_path + 'tr/'\n",
        "base_path_val = base_path + 'v/'\n",
        "base_path_test = base_path + 'te/'\n",
        "\n",
        "base_path_pickle = base_path + 'pickle/'\n",
        "base_path_result = base_path + 'result/'\n",
        "base_path_model = base_path + 'model/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VVGaYrEfaEWU",
        "colab_type": "code",
        "outputId": "1d3ba14a-0ae2-43e2-d92c-9d2f6dff1c0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install librosa"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.6/dist-packages (0.6.3)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (2.1.6)\n",
            "Requirement already satisfied: numpy>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.14.6)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.20.3)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.12.5)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (4.4.0)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.11.0)\n",
            "Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.2.1)\n",
            "Requirement already satisfied: numba>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.40.1)\n",
            "Requirement already satisfied: llvmlite>=0.25.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa) (0.28.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "K9ebAduRaHmw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QPVprwLbaQHf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LiNjwAkyaSVT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6tlbO-UyaXuQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trx = []\n",
        "trs = []\n",
        "trn = []\n",
        "\n",
        "trx_val = []\n",
        "trs_val = []\n",
        "trn_val = []\n",
        "target = []\n",
        "\n",
        "trx_len = []\n",
        "\n",
        "max_width = 513\n",
        "max_length = 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5zHGEhInJQIa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_stft(file_path):\n",
        "  s, sr = librosa.load(file_path, sr=None)\n",
        "  stft = librosa.stft(s, n_fft=1024, hop_length=512).T\n",
        "  return stft"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Onxg0kmxKzKV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_from_directory(directory, file_prefix, all_required):\n",
        "  file_prefix_dirty = file_prefix + 'x'\n",
        "  file_prefix_clean = file_prefix + 's'\n",
        "  file_prefix_noise = file_prefix + 'n'\n",
        "  \n",
        "  lfd_x = []\n",
        "  lfd_s = []\n",
        "  lfd_n = []\n",
        "  lfd_id = []\n",
        "  \n",
        "  n = 0\n",
        "  for file in sorted(os.listdir(directory)): \n",
        "    # consider only .wav files starting with file_prefix_dirty\n",
        "    if file.endswith('.wav') and file.startswith(file_prefix_dirty):\n",
        "      if n % 50 == 0:\n",
        "        print(n, sep='.. ', flush=True)\n",
        "      n += 1\n",
        "      \n",
        "      file_id = file[len(file_prefix_dirty):-len('.wav')]\n",
        "\n",
        "      dirty_file_path = os.path.join(directory, file)\n",
        "\n",
        "      if all_required:\n",
        "        # check if there is corresponding target/clean file\n",
        "        clean_file_name = file.replace(file_prefix_dirty, file_prefix_clean)\n",
        "        clean_file_path = os.path.join(directory, clean_file_name)\n",
        "        if not os.path.exists(clean_file_path):\n",
        "          continue\n",
        "\n",
        "        noise_file_name = file.replace(file_prefix_dirty, file_prefix_noise)\n",
        "        noise_file_path = os.path.join(directory, noise_file_name)\n",
        "        if not os.path.exists(clean_file_path):\n",
        "          continue\n",
        "\n",
        "      # load both dirty, clean and noise files\n",
        "      train_dirty = get_stft(dirty_file_path)\n",
        "      if all_required:\n",
        "        train_clean = get_stft(clean_file_path)\n",
        "        train_noise = get_stft(noise_file_path)\n",
        "      \n",
        "      lfd_x.append(train_dirty)\n",
        "      lfd_id.append(file_id)\n",
        "      \n",
        "      if all_required:\n",
        "        lfd_s.append(train_clean)\n",
        "        lfd_n.append(train_noise)\n",
        "        \n",
        "  if all_required:\n",
        "    return lfd_x, lfd_s, lfd_n, np.array(lfd_id)\n",
        "  return lfd_x, np.array(lfd_id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1ijTE6jBqfre",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def pad_zeros(stft):\n",
        "  stft_val = np.zeros((max_length, max_width))\n",
        "  stft_val[:stft.shape[0], :stft.shape[1]] = np.abs(stft)\n",
        "  return stft_val\n",
        "\n",
        "def get_abs(stft_list):\n",
        "  return np.array([pad_zeros(x) for x in stft_list])\n",
        "\n",
        "def get_len(stft_list):\n",
        "  return np.array([len(x) for x in stft_list])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vsCzFQmBG6Mr",
        "colab_type": "code",
        "outputId": "09ecc40f-fdc2-4bde-bbf1-134d6ed5389a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# check if pickle files exist\n",
        "if os.path.exists(base_path_pickle + 'tr.pickle'):\n",
        "  print('loading pickle...')\n",
        "  with open(base_path_pickle + 'tr.pickle', 'rb') as f:\n",
        "    trx, trs, trn, trx_id = pickle.load(f)\n",
        "  print('loading pickle complete.')\n",
        "else:\n",
        "  print('loading from directory...')\n",
        "  trx, trs, trn, trx_id = load_from_directory(base_path_train, 'tr', True)\n",
        "  print('loading from directory complete. saving...')\n",
        "  with open(base_path_pickle + 'tr.pickle', 'wb') as f:\n",
        "    pickle.dump([trx, trs, trn, trx_id], f)\n",
        "  print('saving complete.')\n",
        "\n",
        "trx_val = get_abs(trx)\n",
        "trs_val = get_abs(trs)\n",
        "trn_val = get_abs(trn)\n",
        "target_tr = 1 * (trs_val > trn_val)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading pickle...\n",
            "loading pickle complete.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "00vSHC4H65ag",
        "colab_type": "code",
        "outputId": "92c6ed5b-2a12-48bd-e033-b6b819fa5576",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(trx)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "MOYN0aNFIC6t",
        "colab_type": "code",
        "outputId": "bb3fb73b-94d1-4634-9293-992c4c3eaa00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "trx_val.shape, trs_val.shape, trn_val.shape, target_tr.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1200, 200, 513), (1200, 200, 513), (1200, 200, 513), (1200, 200, 513))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "fputklBJwsHG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_samples_tr = len(trx_val)\n",
        "batch_size = 20\n",
        "num_features = 513\n",
        "num_hidden = 256\n",
        "\n",
        "learning_rate = 0.001\n",
        "num_epochs = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vn5eY0P5wiD_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = tf.placeholder(tf.float32, [None, max_length, num_features])\n",
        "Y = tf.placeholder(tf.float32, [None, max_length, num_features])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B5pMHqkXv2gd",
        "colab_type": "code",
        "outputId": "7be0686f-eac1-4515-c7dd-5c7859e50c78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "cell_type": "code",
      "source": [
        "cell = tf.nn.rnn_cell.DropoutWrapper(tf.nn.rnn_cell.LSTMCell(num_hidden))\n",
        "output, state = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
        "dense_1 = tf.layers.Dense(units=513, activation=tf.nn.sigmoid)(output)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-17-2c52f2eb71f4>:1: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-17-2c52f2eb71f4>:2: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/tensor_array_ops.py:162: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JFbPl1Bm_cl7",
        "colab_type": "code",
        "outputId": "3200e7f6-aad7-4286-c68f-dd5d18b82461",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "dense_1"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'dense/Sigmoid:0' shape=(?, 200, 513) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "7pKn5pH1uwNa",
        "colab_type": "code",
        "outputId": "20ed4443-372f-4b66-d3ff-e90168c95779",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# calculate loss - only calculate loss on valid data\n",
        "loss = tf.losses.mean_squared_error(labels=Y, predictions=dense_1)\n",
        "train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss=loss)\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:667: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "O8VvjQOBy5Sp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess = tf.Session()\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yflR2Gr6zBRL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "a603607d-6aae-489f-d088-4c4a17b45d03"
      },
      "cell_type": "code",
      "source": [
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  loss_val = 0\n",
        "  for i in range(0, num_samples_tr, batch_size):\n",
        "    start_idx = i\n",
        "    end_idx = min(i + batch_size, num_samples_tr)\n",
        "    \n",
        "    batch_x = trx_val[start_idx:end_idx]\n",
        "    batch_y = target_tr[start_idx:end_idx]\n",
        "    \n",
        "    _, lv = sess.run([train, loss], feed_dict={X: batch_x, Y: batch_y})\n",
        "    loss_val += lv\n",
        "    \n",
        "  if epoch % 5 == 0:\n",
        "    print(epoch, loss_val)\n",
        "    saver.save(sess, base_path_model + 'model_' + str(epoch) + '.ckpt')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 9.076197445392609\n",
            "5 5.339293662458658\n",
            "10 4.675546031445265\n",
            "15 4.366806074976921\n",
            "20 4.098873816430569\n",
            "25 3.925249744206667\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "30 3.8716204948723316\n",
            "35 3.7466445714235306\n",
            "40 3.644021976739168\n",
            "45 3.551829442381859\n",
            "50 3.463367722928524\n",
            "55 3.391324743628502\n",
            "60 3.359113734215498\n",
            "65 3.2617637626826763\n",
            "70 3.2262788265943527\n",
            "75 3.2583462297916412\n",
            "80 3.199598792940378\n",
            "85 3.1560252383351326\n",
            "90 3.50377544388175\n",
            "95 3.1209487933665514\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3Qo4bJXIe3WK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def snr(dirty, clean):\n",
        "  return 10 * np.log10(np.sum(np.square(clean))/np.sum(np.square(clean - dirty)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eIOydmwQBHfU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def save(cleaned, filename):\n",
        "  sh_test = librosa.istft(cleaned.T, hop_length=512)\n",
        "    \n",
        "  # Save to a file\n",
        "  librosa.output.write_wav(filename, sh_test, 16000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "twG9y6_2k-_L",
        "colab_type": "code",
        "outputId": "5463c1e6-d4e3-4e34-c1f0-ec2ff9bd22fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# check if pickle files exist\n",
        "if os.path.exists(base_path_pickle + 'v.pickle'):\n",
        "  print('loading pickle...')\n",
        "  with open(base_path_pickle + 'v.pickle', 'rb') as f:\n",
        "    vx, vs, vn, vx_id = pickle.load(f)\n",
        "  print('loading pickle complete.')\n",
        "else:\n",
        "  print('loading from directory...')\n",
        "  vx, vs, vn, vx_id = load_from_directory(base_path_val, 'v', True)\n",
        "  print('loading from directory complete. saving...')\n",
        "  with open(base_path_pickle + 'v.pickle', 'wb') as f:\n",
        "    pickle.dump([vx, vs, vn, vx_id], f)\n",
        "  print('saving complete.')\n",
        "\n",
        "vx_val = get_abs(vx)\n",
        "vs_val = get_abs(vs)\n",
        "vn_val = get_abs(vn)\n",
        "vx_len = get_len(vx)\n",
        "target_v = 1 * (vs_val > vn_val)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading pickle...\n",
            "loading pickle complete.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pn9FPuN-4rqo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_samples_v = len(vx)\n",
        "total_snr = 0\n",
        "for i in range(0, num_samples_v, batch_size):\n",
        "  start_idx = i\n",
        "  end_idx = min(i + batch_size, num_samples_v)\n",
        "  batch_x = vx_val[start_idx:end_idx]\n",
        "\n",
        "  m_pred = sess.run([dense_1], feed_dict={X: batch_x})\n",
        "  for j in range(start_idx, end_idx):\n",
        "    x = vx[j]\n",
        "    s_val = vs_val[j][:vx_len[j], :]\n",
        "    m = m_pred[0][i - start_idx][:vx_len[j], :]\n",
        "    \n",
        "    cleaned = x * m\n",
        "    fname = base_path_result + 'cleaned' + vx_id[j] + '.wav'\n",
        "    \n",
        "#     save(x * m, fname)\n",
        "    total_snr += snr(np.abs(cleaned), s_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oD0114DL2Isw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "132f5e44-1921-45b6-d86d-572ecfdf041b"
      },
      "cell_type": "code",
      "source": [
        "total_snr/num_samples_v"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.4139119783332035"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "XBPRMds_CL7o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "2388fbd8-1db2-4975-a8ae-b39eaa4bd995"
      },
      "cell_type": "code",
      "source": [
        "print('loading from directory...')\n",
        "tex, tex_id = load_from_directory(base_path_test, 'te', False)\n",
        "print('loading from directory complete.')\n",
        "\n",
        "tex_val = get_abs(tex)\n",
        "tex_len = get_len(tex)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading from directory...\n",
            "0\n",
            "50\n",
            "100\n",
            "150\n",
            "200\n",
            "250\n",
            "300\n",
            "350\n",
            "loading from directory complete.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "E5bXZQbGZHdQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_samples_te = len(tex)\n",
        "\n",
        "for i in range(0, num_samples_te, batch_size):\n",
        "  start_idx = i\n",
        "  end_idx = min(i + batch_size, num_samples_te)\n",
        "  \n",
        "  batch_x = tex_val[start_idx:end_idx]\n",
        "\n",
        "  m_pred = sess.run([dense_1], feed_dict={X: batch_x})\n",
        "  for j in range(start_idx, end_idx):\n",
        "    x = tex[j]\n",
        "    s = tex_val[j][:tex_len[j], :]\n",
        "    m = m_pred[0][i - start_idx][:tex_len[j], :]\n",
        "    \n",
        "    cleaned = x * m\n",
        "    fname = base_path_result + 'cleaned' + tex_id[j] + '.wav'\n",
        "    \n",
        "#     save(x * m, fname)\n",
        "    total_snr += snr(s, np.abs(cleaned))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XQ1IrleJjXNp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}