{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "speech-denoising-using-lstm.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "TRJwZmWFZVUH",
        "colab_type": "code",
        "outputId": "84a36a58-edd2-47f8-d782-8020069f6540",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bBe8sG2ZaCm1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "base_path = './drive/My Drive/Colab Notebooks/Speech Denoising/LotOfData/'\n",
        "\n",
        "base_path_train = base_path + 'tr/'\n",
        "base_path_val = base_path + 'v/'\n",
        "base_path_test = base_path + 'te/'\n",
        "\n",
        "base_path_pickle = base_path + 'pickle/'\n",
        "base_path_result = base_path + 'result/'\n",
        "base_path_model = base_path + 'model/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VVGaYrEfaEWU",
        "colab_type": "code",
        "outputId": "40e63b87-4c3d-4a7f-a7d5-34b0c00d83d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install librosa"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.6/dist-packages (0.6.3)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (2.1.6)\n",
            "Requirement already satisfied: numpy>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.14.6)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.20.3)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.12.5)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (4.4.0)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.11.0)\n",
            "Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.2.1)\n",
            "Requirement already satisfied: numba>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.40.1)\n",
            "Requirement already satisfied: llvmlite>=0.25.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa) (0.28.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "K9ebAduRaHmw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QPVprwLbaQHf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LiNjwAkyaSVT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6tlbO-UyaXuQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trx = []\n",
        "trs = []\n",
        "trn = []\n",
        "\n",
        "trx_val = []\n",
        "trs_val = []\n",
        "trn_val = []\n",
        "target = []\n",
        "\n",
        "trx_len = []\n",
        "\n",
        "max_width = 513\n",
        "max_length = 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5zHGEhInJQIa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_stft(file_path):\n",
        "  s, sr = librosa.load(file_path, sr=None)\n",
        "  stft = librosa.stft(s, n_fft=1024, hop_length=512).T\n",
        "  return stft"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Onxg0kmxKzKV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_from_directory(directory, file_prefix, all_required):\n",
        "  file_prefix_dirty = file_prefix + 'x'\n",
        "  file_prefix_clean = file_prefix + 's'\n",
        "  file_prefix_noise = file_prefix + 'n'\n",
        "  \n",
        "  lfd_x = []\n",
        "  lfd_s = []\n",
        "  lfd_n = []\n",
        "  lfd_id = []\n",
        "  \n",
        "  n = 0\n",
        "  for file in sorted(os.listdir(directory)): \n",
        "    # consider only .wav files starting with file_prefix_dirty\n",
        "    if file.endswith('.wav') and file.startswith(file_prefix_dirty):\n",
        "      if n % 50 == 0:\n",
        "        print(n, sep='.. ', flush=True)\n",
        "      n += 1\n",
        "      \n",
        "      file_id = file[len(file_prefix_dirty):-len('.wav')]\n",
        "\n",
        "      dirty_file_path = os.path.join(directory, file)\n",
        "\n",
        "      if all_required:\n",
        "        # check if there is corresponding target/clean file\n",
        "        clean_file_name = file.replace(file_prefix_dirty, file_prefix_clean)\n",
        "        clean_file_path = os.path.join(directory, clean_file_name)\n",
        "        if not os.path.exists(clean_file_path):\n",
        "          continue\n",
        "\n",
        "        noise_file_name = file.replace(file_prefix_dirty, file_prefix_noise)\n",
        "        noise_file_path = os.path.join(directory, noise_file_name)\n",
        "        if not os.path.exists(clean_file_path):\n",
        "          continue\n",
        "\n",
        "      # load both dirty, clean and noise files\n",
        "      train_dirty = get_stft(dirty_file_path)\n",
        "      if all_required:\n",
        "        train_clean = get_stft(clean_file_path)\n",
        "        train_noise = get_stft(noise_file_path)\n",
        "      \n",
        "      lfd_x.append(train_dirty)\n",
        "      lfd_id.append(file_id)\n",
        "      \n",
        "      if all_required:\n",
        "        lfd_s.append(train_clean)\n",
        "        lfd_n.append(train_noise)\n",
        "        \n",
        "  if all_required:\n",
        "    return lfd_x, lfd_s, lfd_n, np.array(lfd_id)\n",
        "  return lfd_x, np.array(lfd_id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1ijTE6jBqfre",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def pad_zeros(stft):\n",
        "  stft_val = np.zeros((max_length, max_width))\n",
        "  stft_val[:stft.shape[0], :stft.shape[1]] = np.abs(stft)\n",
        "  return stft_val\n",
        "\n",
        "def get_abs(stft_list):\n",
        "  return np.array([pad_zeros(x) for x in stft_list])\n",
        "\n",
        "def get_len(stft_list):\n",
        "  return np.array([len(x) for x in stft_list])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vsCzFQmBG6Mr",
        "colab_type": "code",
        "outputId": "e3c3dbbd-b099-4b73-fc28-9de060d001ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# check if pickle files exist\n",
        "if os.path.exists(base_path_pickle + 'tr.pickle'):\n",
        "  print('loading pickle...')\n",
        "  with open(base_path_pickle + 'tr.pickle', 'rb') as f:\n",
        "    trx, trs, trn, trx_id = pickle.load(f)\n",
        "  print('loading pickle complete.')\n",
        "else:\n",
        "  print('loading from directory...')\n",
        "  trx, trs, trn, trx_id = load_from_directory(base_path_train, 'tr', True)\n",
        "  print('loading from directory complete. saving...')\n",
        "  with open(base_path_pickle + 'tr.pickle', 'wb') as f:\n",
        "    pickle.dump([trx, trs, trn, trx_id], f)\n",
        "  print('saving complete.')\n",
        "\n",
        "trx_val = get_abs(trx)\n",
        "trs_val = get_abs(trs)\n",
        "trn_val = get_abs(trn)\n",
        "target_tr = 1 * (trs_val > trn_val)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading pickle...\n",
            "loading pickle complete.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "00vSHC4H65ag",
        "colab_type": "code",
        "outputId": "547dd769-68cf-4452-9fd9-8a46382d11cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(trx)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "MOYN0aNFIC6t",
        "colab_type": "code",
        "outputId": "54d7d4e3-86fa-4c50-c6f1-c22766c51837",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "trx_val.shape, trs_val.shape, trn_val.shape, target_tr.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1200, 200, 513), (1200, 200, 513), (1200, 200, 513), (1200, 200, 513))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "fputklBJwsHG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_samples_tr = len(trx_val)\n",
        "batch_size = 20\n",
        "num_features = 513\n",
        "num_hidden = 256\n",
        "\n",
        "learning_rate = 0.001\n",
        "num_epochs = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vn5eY0P5wiD_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = tf.placeholder(tf.float32, [None, max_length, num_features])\n",
        "Y = tf.placeholder(tf.float32, [None, max_length, num_features])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B5pMHqkXv2gd",
        "colab_type": "code",
        "outputId": "d5f22bdc-546a-4ea7-bf73-2069999e01d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "cell_type": "code",
      "source": [
        "cell = tf.nn.rnn_cell.DropoutWrapper(tf.nn.rnn_cell.LSTMCell(num_hidden))\n",
        "output, state = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
        "dense_1 = tf.layers.Dense(units=513, activation=tf.nn.sigmoid)(output)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-16-2c52f2eb71f4>:1: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-16-2c52f2eb71f4>:2: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/tensor_array_ops.py:162: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JFbPl1Bm_cl7",
        "colab_type": "code",
        "outputId": "8ff15ae5-195e-40fa-ee7c-ef0ee4ef3748",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "dense_1"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'dense/Sigmoid:0' shape=(?, 200, 513) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "7pKn5pH1uwNa",
        "colab_type": "code",
        "outputId": "7da104e8-ec16-4d90-cc74-a79cae17f8ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# calculate loss - only calculate loss on valid data\n",
        "loss = tf.losses.mean_squared_error(labels=Y, predictions=dense_1)\n",
        "train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss=loss)\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:667: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "O8VvjQOBy5Sp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess = tf.Session()\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yflR2Gr6zBRL",
        "colab_type": "code",
        "outputId": "06852524-73ab-46c0-eadd-e1ca3ea0fafd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "saver.restore(sess, base_path_model + 'model_95.ckpt')\n",
        "\n",
        "# for epoch in range(num_epochs):\n",
        "#   loss_val = 0\n",
        "#   for i in range(0, num_samples_tr, batch_size):\n",
        "#     start_idx = i\n",
        "#     end_idx = min(i + batch_size, num_samples_tr)\n",
        "    \n",
        "#     batch_x = trx_val[start_idx:end_idx]\n",
        "#     batch_y = target_tr[start_idx:end_idx]\n",
        "    \n",
        "#     _, lv = sess.run([train, loss], feed_dict={X: batch_x, Y: batch_y})\n",
        "#     loss_val += lv\n",
        "    \n",
        "#   if epoch % 5 == 0:\n",
        "#     print(epoch, loss_val)\n",
        "#     saver.save(sess, base_path_model + 'model_' + str(epoch) + '.ckpt')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from ./drive/My Drive/Colab Notebooks/Speech Denoising/LotOfData/model/model_95.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3Qo4bJXIe3WK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def snr(dirty, clean):\n",
        "  return 10 * np.log10(np.sum(np.square(clean))/np.sum(np.square(clean - dirty)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eIOydmwQBHfU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def save(cleaned, filename):\n",
        "  sh_test = librosa.istft(cleaned.T, hop_length=512)\n",
        "    \n",
        "  # Save to a file\n",
        "  librosa.output.write_wav(filename, sh_test, 16000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "twG9y6_2k-_L",
        "colab_type": "code",
        "outputId": "201dbda6-0d24-46c9-ab8f-8bf50bccfbe9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# check if pickle files exist\n",
        "if os.path.exists(base_path_pickle + 'v.pickle'):\n",
        "  print('loading pickle...')\n",
        "  with open(base_path_pickle + 'v.pickle', 'rb') as f:\n",
        "    vx, vs, vn, vx_id = pickle.load(f)\n",
        "  print('loading pickle complete.')\n",
        "else:\n",
        "  print('loading from directory...')\n",
        "  vx, vs, vn, vx_id = load_from_directory(base_path_val, 'v', True)\n",
        "  print('loading from directory complete. saving...')\n",
        "  with open(base_path_pickle + 'v.pickle', 'wb') as f:\n",
        "    pickle.dump([vx, vs, vn, vx_id], f)\n",
        "  print('saving complete.')\n",
        "\n",
        "vx_val = get_abs(vx)\n",
        "vs_val = get_abs(vs)\n",
        "vn_val = get_abs(vn)\n",
        "vx_len = get_len(vx)\n",
        "target_v = 1 * (vs_val > vn_val)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading pickle...\n",
            "loading pickle complete.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pn9FPuN-4rqo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_samples_v = len(vx)\n",
        "total_snr = 0\n",
        "num, den = 0, 0\n",
        "\n",
        "for i in range(0, num_samples_v, batch_size):\n",
        "  start_idx = i\n",
        "  end_idx = min(i + batch_size, num_samples_v)\n",
        "  batch_x = vx_val[start_idx:end_idx]\n",
        "\n",
        "  m_pred = sess.run([dense_1], feed_dict={X: batch_x})\n",
        "  for j in range(start_idx, end_idx):\n",
        "    x = vx[j]\n",
        "    s_val = vs_val[j][:vx_len[j], :]\n",
        "    m = m_pred[0][j - start_idx][:vx_len[j], :]\n",
        "    \n",
        "    cleaned = x * m\n",
        "    fname = base_path_result + 'cleaned' + vx_id[j] + '.wav'\n",
        "    \n",
        "#     save(x * m, fname)\n",
        "    num += np.sum(np.square(s_val))\n",
        "    den += np.sum(np.square(s_val - np.abs(cleaned)))\n",
        "\n",
        "snr_val = 10 * np.log10(num/den)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oD0114DL2Isw",
        "colab_type": "code",
        "outputId": "7bb301dc-8c5c-4d7b-96fc-e05683e425e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "snr_val"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10.595921530168525"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "XBPRMds_CL7o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "d57ce713-cb48-4fe7-eb6a-707acebd7f3d"
      },
      "cell_type": "code",
      "source": [
        "print('loading from directory...')\n",
        "tex, tex_id = load_from_directory(base_path_test, 'te', False)\n",
        "print('loading from directory complete.')\n",
        "\n",
        "tex_val = get_abs(tex)\n",
        "tex_len = get_len(tex)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading from directory...\n",
            "0\n",
            "50\n",
            "100\n",
            "150\n",
            "200\n",
            "250\n",
            "300\n",
            "350\n",
            "loading from directory complete.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "E5bXZQbGZHdQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_samples_te = len(tex)\n",
        "\n",
        "for i in range(0, num_samples_te, batch_size):\n",
        "  start_idx = i\n",
        "  end_idx = min(i + batch_size, num_samples_te)\n",
        "  \n",
        "  batch_x = tex_val[start_idx:end_idx]\n",
        "\n",
        "  m_pred = sess.run([dense_1], feed_dict={X: batch_x})\n",
        "  for j in range(start_idx, end_idx):\n",
        "    x = tex[j]\n",
        "    s = tex_val[j][:tex_len[j], :]\n",
        "    m = m_pred[0][j - start_idx][:tex_len[j], :]\n",
        "    \n",
        "    cleaned = x * m\n",
        "    fname = base_path_result + 'cleaned' + tex_id[j] + '.wav'\n",
        "    save(x * m, fname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XQ1IrleJjXNp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}