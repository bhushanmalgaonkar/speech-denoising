{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "speech-denoising-using-2d-cnn.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "A22u46Yz9dZt",
        "colab_type": "code",
        "outputId": "53c4aa67-2b0c-40ad-d769-3f7b6ee9a2db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "A6IhYmaK9dZ-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "base_path = './drive/My Drive/Colab Notebooks/Speech Denoising/Data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NkkIBfrb9daL",
        "colab_type": "code",
        "outputId": "b0e90406-af7f-461e-bd26-c174db763a32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install librosa"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.6/dist-packages (0.6.3)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (2.1.6)\n",
            "Requirement already satisfied: numpy>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.14.6)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.20.2)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.13.2)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (4.3.2)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.11.0)\n",
            "Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.2.1)\n",
            "Requirement already satisfied: numba>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.40.1)\n",
            "Requirement already satisfied: llvmlite>=0.25.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa) (0.27.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s3KwRQm39daY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import librosa"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VNFy40WH9dal",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "from time import time\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s2NGSRHz9daz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "34VCg8v19dbB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "s, sr=librosa.load(base_path + 'train_clean_male.wav', sr=None)\n",
        "train_clean=librosa.stft(s, n_fft=1024, hop_length=512).T\n",
        "\n",
        "sn, sr=librosa.load(base_path + 'train_dirty_male.wav', sr=None)\n",
        "train_dirty=librosa.stft(sn, n_fft=1024, hop_length=512).T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cEYknx4N9dbK",
        "colab_type": "code",
        "outputId": "f88c776e-883c-4b9a-f182-b928486971f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_clean.shape, train_dirty.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2459, 513), (2459, 513))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "KT6kMu2q9dbS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Take magnitudes of audio signals"
      ]
    },
    {
      "metadata": {
        "id": "fF9vQnnq9dbT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_clean_val = np.abs(train_clean)\n",
        "train_dirty_val = np.abs(train_dirty)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pe3fc4CM9dbZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Check bounds of absolute values"
      ]
    },
    {
      "metadata": {
        "id": "tlGvTOFk9dba",
        "colab_type": "code",
        "outputId": "cd1c662e-30fa-43c1-f092-fb45b824b104",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "print(f'min(train_clean_val) = {np.min(train_clean_val)}, max(train_clean_val) = {np.max(train_clean_val)}')\n",
        "print(f'min(train_dirty_val) = {np.min(train_dirty_val)}, max(train_dirty_val) = {np.max(train_dirty_val)}')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "min(train_clean_val) = 2.724569583278935e-07, max(train_clean_val) = 31.574600219726562\n",
            "min(train_dirty_val) = 3.297913409028297e-08, max(train_dirty_val) = 31.603910446166992\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XenCp9OT9dbg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training"
      ]
    },
    {
      "metadata": {
        "id": "_9HTvGK09dbh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Split the data into training and validation set"
      ]
    },
    {
      "metadata": {
        "id": "ZFA6a4dM9dbj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(train_dirty_val, train_clean_val, test_size=0.2, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dZzyba-Gf4A-",
        "colab_type": "code",
        "outputId": "82b50eb5-c0e7-481f-95eb-b9dee2db0afa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1967, 513), (492, 513))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "5AIGM_XQ9dbp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define tensorflow variables for the model\n"
      ]
    },
    {
      "metadata": {
        "id": "AxKfF-zV9db2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "IMAGE_HEIGHT = 20\n",
        "IMAGE_WIDTH = X_train.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LC5F71K-RS4s",
        "colab_type": "code",
        "outputId": "92b93e92-6bf9-492e-fd23-ddab1be55dd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "X = tf.placeholder(dtype='float', shape=[None, IMAGE_HEIGHT, IMAGE_WIDTH, 1])\n",
        "Y = tf.placeholder(dtype='float', shape=[None, IMAGE_HEIGHT, IMAGE_WIDTH, 1])\n",
        "\n",
        "dropout_X = tf.layers.Dropout(rate=0.4)(X)\n",
        "\n",
        "conv_1 = tf.layers.Conv2D(filters=8, kernel_size=(5, 5), strides=(3, 3), padding='same', data_format='channels_last', activation=tf.nn.relu)(dropout_X)\n",
        "pool_1 = tf.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1))(conv_1)\n",
        "bn_1 = tf.layers.BatchNormalization()(pool_1)\n",
        "\n",
        "dropout_1 = tf.layers.Dropout(rate=0.4)(bn_1)\n",
        "\n",
        "# conv_2 = tf.layers.Conv2D(filters=16, kernel_size=(3, 3), strides=(1, 1), padding='same', data_format='channels_last', activation=tf.nn.relu)(dropout_1)\n",
        "# pool_2 = tf.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(conv_2)\n",
        "# bn_2 = tf.layers.BatchNormalization()(pool_2)\n",
        "\n",
        "# dropout_2 = tf.layers.Dropout(rate=0.2)(bn_2)\n",
        "\n",
        "flattened = tf.layers.Flatten()(dropout_1)\n",
        "dense_1 = tf.layers.Dense(units=IMAGE_HEIGHT * IMAGE_WIDTH, activation=tf.nn.relu)(flattened)\n",
        "output = tf.reshape(dense_1, shape=[-1, IMAGE_HEIGHT, IMAGE_WIDTH, 1])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "A0q5OGq5YuvZ",
        "colab_type": "code",
        "outputId": "7e646211-744d-4fda-c028-7ffc16602eea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "cell_type": "code",
      "source": [
        "for layer in [X, dropout_X, conv_1, pool_1, bn_1, dropout_1, flattened, dense_1, output]:\n",
        "  print('{:100} ? * {:d}'.format(str(layer), np.prod([x.value for x in layer.shape[1:]])))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Placeholder:0\", shape=(?, 20, 513, 1), dtype=float32)                                        ? * 10260\n",
            "Tensor(\"dropout/Identity:0\", shape=(?, 20, 513, 1), dtype=float32)                                   ? * 10260\n",
            "Tensor(\"conv2d/Relu:0\", shape=(?, 7, 171, 8), dtype=float32)                                         ? * 9576\n",
            "Tensor(\"max_pooling2d/MaxPool:0\", shape=(?, 6, 170, 8), dtype=float32)                               ? * 8160\n",
            "Tensor(\"batch_normalization/FusedBatchNorm:0\", shape=(?, 6, 170, 8), dtype=float32)                  ? * 8160\n",
            "Tensor(\"dropout_1/Identity:0\", shape=(?, 6, 170, 8), dtype=float32)                                  ? * 8160\n",
            "Tensor(\"flatten/Reshape:0\", shape=(?, 8160), dtype=float32)                                          ? * 8160\n",
            "Tensor(\"dense/Relu:0\", shape=(?, 10260), dtype=float32)                                              ? * 10260\n",
            "Tensor(\"Reshape:0\", shape=(?, 20, 513, 1), dtype=float32)                                            ? * 10260\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ECzOT6iXt0i9",
        "colab_type": "code",
        "outputId": "cd785864-681d-47f8-8fb4-309e03778cfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "learning_rate = 0.0004\n",
        "\n",
        "loss = tf.losses.mean_squared_error(labels=Y, predictions=output)\n",
        "train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss=loss)\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:667: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "G31h3--KyPrl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 512\n",
        "num_epochs = 500\n",
        "display_step = 100\n",
        "log_step = 100\n",
        "\n",
        "total_samples_train = X_train.shape[0] - IMAGE_HEIGHT\n",
        "total_samples_test = X_test.shape[0] - IMAGE_HEIGHT\n",
        "num_batches_train = int(math.ceil(total_samples_train/batch_size))\n",
        "num_batches_test = int(math.ceil(total_samples_test/batch_size))\n",
        "\n",
        "train_loss = []\n",
        "test_loss = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QYFpcD_234uh",
        "colab_type": "code",
        "outputId": "b2f99234-af4f-485b-b980-e0f556f26280",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "cell_type": "code",
      "source": [
        "st = time()\n",
        "\n",
        "sess = tf.Session()\n",
        "\n",
        "sess.run(init)\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "  for itr in range(num_batches_train):\n",
        "    start_idx = itr * batch_size\n",
        "    end_idx = min((itr + 1) * batch_size, total_samples_train)\n",
        "    \n",
        "    # as is\n",
        "    batch_x = np.array([X_train[i:i + IMAGE_HEIGHT] for i in range(start_idx, end_idx)]).reshape(-1, IMAGE_HEIGHT, IMAGE_WIDTH, 1)\n",
        "    batch_y = np.array([y_train[i:i + IMAGE_HEIGHT] for i in range(start_idx, end_idx)]).reshape(-1, IMAGE_HEIGHT, IMAGE_WIDTH, 1)\n",
        "    sess.run(train, feed_dict={X:batch_x, Y:batch_y})\n",
        "    \n",
        "    # filp vertically\n",
        "#     batch_x_v_flip = np.array([p[::-1] for p in batch_x])\n",
        "#     batch_y_v_flip = np.array([p[::-1] for p in batch_y])\n",
        "#     sess.run(train, feed_dict={X:batch_x_v_flip, Y:batch_y_v_flip})\n",
        "    \n",
        "#     # flip horizontally\n",
        "#     batch_x_h_flip = np.array([p[::-1] for q in batch_x for p in q]).reshape(-1, IMAGE_HEIGHT, IMAGE_WIDTH, 1)\n",
        "#     batch_y_h_flip = np.array([p[::-1] for q in batch_y for p in q]).reshape(-1, IMAGE_HEIGHT, IMAGE_WIDTH, 1)\n",
        "#     sess.run(train, feed_dict={X:batch_x_h_flip, Y:batch_y_h_flip})\n",
        "    \n",
        "#     # flip vertically and horizontally\n",
        "#     batch_x_hv_flip = np.array([p[::-1] for p in batch_x_h_flip])\n",
        "#     batch_y_hv_flip = np.array([p[::-1] for p in batch_y_h_flip])\n",
        "#     sess.run(train, feed_dict={X:batch_x_hv_flip, Y:batch_y_hv_flip})\n",
        "    \n",
        "  if epoch % log_step == 0:\n",
        "    # calculate loss for entire training and testing set\n",
        "    trls = 0\n",
        "    for itr in range(num_batches_train):\n",
        "      start_idx = itr * batch_size\n",
        "      end_idx = min((itr + 1) * batch_size, total_samples_train)\n",
        "      \n",
        "      batch_x = np.array([X_train[i:i + IMAGE_HEIGHT] for i in range(start_idx, end_idx)]).reshape(-1, IMAGE_HEIGHT, IMAGE_WIDTH, 1)\n",
        "      batch_y = np.array([y_train[i:i + IMAGE_HEIGHT] for i in range(start_idx, end_idx)]).reshape(-1, IMAGE_HEIGHT, IMAGE_WIDTH, 1)\n",
        "      \n",
        "      trls += sess.run(loss, feed_dict={X:batch_x, Y:batch_y})\n",
        "      \n",
        "    tsls = 0\n",
        "    for itr in range(num_batches_test):\n",
        "      start_idx = itr * batch_size\n",
        "      end_idx = min((itr + 1) * batch_size, total_samples_test)\n",
        "\n",
        "      batch_x = np.array([X_test[i:i + IMAGE_HEIGHT] for i in range(start_idx, end_idx)]).reshape(-1, IMAGE_HEIGHT, IMAGE_WIDTH, 1)\n",
        "      batch_y = np.array([y_test[i:i + IMAGE_HEIGHT] for i in range(start_idx, end_idx)]).reshape(-1, IMAGE_HEIGHT, IMAGE_WIDTH, 1)\n",
        "      \n",
        "      tsls += sess.run(loss, feed_dict={X:batch_x, Y:batch_y})\n",
        "    \n",
        "    # average loss\n",
        "    trls /= total_samples_train\n",
        "    tsls /= total_samples_test\n",
        "    \n",
        "    train_loss.append(trls)\n",
        "    test_loss.append(tsls)\n",
        "    \n",
        "  if epoch % display_step == 0:\n",
        "    print(f'Finished epoch:{epoch}')\n",
        "    print(f'Train set:\\tLoss:{trls:.8f}')\n",
        "    print(f'Test set:\\tLoss:{tsls:.8f}\\n')\n",
        "    \n",
        "print('Time taken: ', (time() - st), 'sec')\n",
        "print('Time per epoch: ', (time() - st)/num_epochs, 'sec')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished epoch:100\n",
            "Train set:\tLoss:0.00002248\n",
            "Test set:\tLoss:0.00011091\n",
            "\n",
            "Finished epoch:200\n",
            "Train set:\tLoss:0.00001588\n",
            "Test set:\tLoss:0.00011028\n",
            "\n",
            "Finished epoch:300\n",
            "Train set:\tLoss:0.00001427\n",
            "Test set:\tLoss:0.00011158\n",
            "\n",
            "Finished epoch:400\n",
            "Train set:\tLoss:0.00001366\n",
            "Test set:\tLoss:0.00011168\n",
            "\n",
            "Finished epoch:500\n",
            "Train set:\tLoss:0.00001317\n",
            "Test set:\tLoss:0.00011226\n",
            "\n",
            "Time taken:  330.39452958106995 sec\n",
            "Time per epoch:  0.6607902011871338 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BN755TvE5-2G",
        "colab_type": "code",
        "outputId": "e64e115f-ef53-460c-e04b-d7c55344b4a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "cell_type": "code",
      "source": [
        "plt.plot(train_loss)\n",
        "plt.plot(test_loss)\n",
        "plt.legend(['Training loss', 'Validation loss'])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f6ef85580f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAD4CAYAAAD2FnFTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "mlc2Twyb9dcU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Prediction"
      ]
    },
    {
      "metadata": {
        "id": "Un96kFAc9dcW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def parse_audio_file(filename):\n",
        "  # load audio file\n",
        "  s, sr = librosa.load(filename, sr=None)\n",
        "\n",
        "  # apply short time fourier transform\n",
        "  dirty = librosa.stft(s, n_fft=1024, hop_length=512).T\n",
        "\n",
        "  # take magnitudes of audio signals\n",
        "  dirty_val = np.abs(dirty)\n",
        "\n",
        "  return dirty, dirty_val\n",
        "  \n",
        "def clean_audio(dirty_val):    \n",
        "    total_samples = dirty_val.shape[0]\n",
        "    num_batches = int(math.ceil(total_samples/IMAGE_HEIGHT))\n",
        "    \n",
        "    # run it through the neural network to remove noisy bits\n",
        "    clean_val = np.empty(shape=(0, IMAGE_WIDTH), dtype='float')\n",
        "    for itr in range(num_batches):\n",
        "      start_idx = itr * IMAGE_HEIGHT\n",
        "      end_idx = (itr + 1) * IMAGE_HEIGHT\n",
        "      \n",
        "      if end_idx > total_samples:\n",
        "        # this iteration does not have enough rows to make full image\n",
        "        op = np.random.random(size=(total_samples - start_idx, IMAGE_WIDTH)) * 0.001\n",
        "      else:\n",
        "        batch_x = dirty_val[start_idx:end_idx].reshape(-1, IMAGE_HEIGHT, IMAGE_WIDTH, 1)\n",
        "        batch_y = dirty_val[start_idx:end_idx].reshape(-1, IMAGE_HEIGHT, IMAGE_WIDTH, 1)\n",
        "        op = sess.run(output, feed_dict={X:batch_x, Y:batch_y})\n",
        "        op = op.reshape(-1, IMAGE_WIDTH)\n",
        "        \n",
        "      clean_val = np.concatenate([clean_val, op], axis=0)\n",
        "      \n",
        "    return clean_val\n",
        "    \n",
        "def save_as_audio(dirty, dirty_val, clean_val, to_filename):\n",
        "  # recover speech spectogram of the cleaned signal\n",
        "  cleaned = np.multiply(np.divide(dirty.T, dirty_val.T), clean_val.T)\n",
        "  \n",
        "  # recover time domain speech signal by applying inverse short time fourier transform\n",
        "  sh_test = librosa.istft(cleaned, hop_length=512)\n",
        "\n",
        "  # Save to a file\n",
        "  librosa.output.write_wav(to_filename, sh_test, sr)\n",
        "  print('Saved to ', to_filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZJ2seYjt-8Vk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def save_cleaned(input_filename, save_filename):\n",
        "  dirty, dirty_val = parse_audio_file(input_filename)\n",
        "  clean_val = clean_audio(dirty_val)\n",
        "  save_as_audio(dirty, dirty_val, clean_val, save_filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mNtJakJXD7tP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Calculate Signal-to-Noise Ratio using following formula\n",
        "\n",
        "<img src=\"https://d1b10bmlvqabco.cloudfront.net/attach/jqcgj7tyoxz6oi/jl5gazm4ih22q1/jrx4uo8px5hd/SNR.JPG\" width=\"400\">\n"
      ]
    },
    {
      "metadata": {
        "id": "27OWiFanEBU0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def snr(dirty, clean):\n",
        "  clean_val = clean_audio(dirty)\n",
        "  return 10 * np.log10(np.sum(np.square(clean))/np.sum(np.square(clean - clean_val)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "In-XucNREHOM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### SNR for training data"
      ]
    },
    {
      "metadata": {
        "id": "M9Lxs-nFEL6N",
        "colab_type": "code",
        "outputId": "3ee3c6d7-3da0-4939-c791-5e142597519a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "snr(clean_audio(X_train), y_train)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.9824129054365365"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "d6rXtY4jEOaa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### SNR for validation data"
      ]
    },
    {
      "metadata": {
        "id": "OQWqihOqEcdc",
        "colab_type": "code",
        "outputId": "7f140566-0f46-4b8e-e203-ddc86b6d6def",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "snr(clean_audio(X_test), y_test)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.3019775850783826"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "1y_iWrxa9dco",
        "colab_type": "code",
        "outputId": "c62ce78b-734a-4dbb-cc07-841c59140818",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "save_cleaned(base_path + 'test_x_01.wav', base_path + 'test_x_01_cleaned.wav')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved to  ./drive/My Drive/Colab Notebooks/Speech Denoising/Data/test_x_01_cleaned.wav\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "r2eSLZSt9dcz",
        "colab_type": "code",
        "outputId": "6977b83a-8975-4c47-e16e-ed280bfaf1a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "save_cleaned(base_path + 'test_x_02.wav', base_path + 'test_x_02_cleaned.wav')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved to  ./drive/My Drive/Colab Notebooks/Speech Denoising/Data/test_x_02_cleaned.wav\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "m3NbPkWTqv2h",
        "colab_type": "code",
        "outputId": "efc396c3-b8c3-41b1-bbc0-19d45f272b54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "save_cleaned(base_path + 'train_dirty_male.wav', base_path + 'train_dirty_male_cleaned.wav')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved to  ./drive/My Drive/Colab Notebooks/Speech Denoising/Data/train_dirty_male_cleaned.wav\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DxlzFhpe9dc6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# sess.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HRRrlkD-A9ij",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}